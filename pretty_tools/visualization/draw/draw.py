"""
.. note::

    torch éšå¼ä¾èµ–ï¼Œåªæœ‰é€šè¿‡æ˜¾ç¤ºè°ƒç”¨æ‰ä¼šå¼ºåˆ¶ä½¿ç”¨torch

.. note::

    åç»­è¿™é‡Œçš„ç»˜åˆ¶å·¥å…·åº”å½“è¿›è¡Œæ”¹è¿›ï¼Œä¸åº”è¯¥å†ä½¿ç”¨ :class:`mdict` äº†ï¼Œmdicté€‚åˆè¿›è¡Œæ•°æ®çš„å†™å…¥ï¼Œ
    ä½†æ˜¯åœ¨è¿›è¡Œå¤„ç†çš„æ—¶å€™æ²¡æ³•æ‰¹é‡è°ƒç”¨ï¼Œä¹‹åå†™çš„å·¥å…·å‡½æ•°åº”å½“è§„é¿æ‰è¿™ä¸€ç‚¹ï¼Œä¸å†ä½¿ç”¨ **mdict**

.. important::

    è¿™ä¸ªæ¨¡å—è§„å®šäº†å…¨å±€çš„å­—ä½“æ ¼å¼ä¸º ``Times New Roman`` å­—ä½“


.. important::

    1. ç»˜å›¾ç›¸å…³çš„æ•°æ®å»ºè®®å…¨éƒ¨é‡‡ç”¨ :class:`numpy` æˆ–è€… :class:`scipy.sparse.spmatrix` ç±»å‹
    2. è¯·ä¸è¦ä½¿ç”¨ :class:`torch` è¿›è¡Œå¼€å‘ï¼Œå› ä¸ºæœ‰çš„é¡¹ç›®å¹¶ä¸å®‰è£… torchï¼Œå½“æ¶‰åŠåˆ°è¿™ä¸ª draw çš„ åŠŸèƒ½çš„æ—¶å€™ï¼Œå²‚ä¸æ˜¯è¦å¼ºåˆ¶å®‰è£…ä¸€ä¸ª torchï¼Ÿ
    å»ºè®®é€šè¿‡åˆ¤ç«¯ ``type(data) == "<class 'torch.Tensor'>"`` æ¥åˆ¤ç«¯æ˜¯å¦æ˜¯ :class:`torch` ç±»å‹çš„æ•°æ®ï¼Œå¹¶é€šè¿‡è°ƒç”¨ :func:`numpy()` å°†å…¶è½¬æ¢æˆ numpy ç±»å‹ã€‚

"""

import copy
import itertools
import math
import sys
from copy import deepcopy
from functools import partial
from typing import Any, Dict, List, Literal, Optional, Sequence, Tuple, Union

import cv2
import matplotlib
import matplotlib.transforms as mtransforms
import numpy as np
import seaborn as sns
from matplotlib import font_manager as fm
from matplotlib import pyplot as plt
from matplotlib.pyplot import Figure
from matplotlib.axes import Axes
from matplotlib.gridspec import GridSpec
from matplotlib.offsetbox import AnnotationBbox, OffsetImage
from matplotlib.patches import ConnectionPatch
from pandas import DataFrame
from PIL import Image, ImageDraw, ImageFont

# * å¤„ç†éƒ¨åˆ†éœ€è¦ä½¿ç”¨åˆ°torchçš„åº“
try:
    import torch
except:
    pass
try:
    from pretty_tools.datastruct import graph_enhance, np_enhance
except:
    pass
from pretty_tools.datastruct.bbox_convert import dict_convert_fn
from pretty_tools.datastruct.cython_bbox import cy_bbox_overlaps_iou
from pretty_tools.datastruct.multi_index_dict import mdict
from pretty_tools.datastruct.np_enhance import convert_to_numpy
from pretty_tools.datastruct.numpy_bbox import bbox_no_overlaps_area
from pretty_tools.resources import path_font_arial, path_font_time_new_roman
from pretty_tools.solver.match_utils import match_result_check
from scipy import sparse

from . import matplotlib_misc

matplotlib.use("Agg")

#! æŒ‰ç…§è§„å®šï¼Œå­—ä½“åº”å½“ä½¿ç”¨ æ–°ç½—é©¬å­—ä½“
font = {"family": "serif", "serif": "Times New Roman", "weight": "normal", "size": 10}
plt.rc("font", **font)
font_time_new_roman = matplotlib.font_manager.FontProperties(fname=str(path_font_time_new_roman))


class Visiual_Tools:
    @staticmethod
    def convert_img(img):
        if type(img) == np.ndarray:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(img)
        assert type(img) == Image.Image
        return img

    @staticmethod
    def get_wh(image: Union[np.ndarray, Image.Image]) -> Tuple[int, int]:
        if isinstance(image, np.ndarray):
            return image.shape[1::-1]  # type: ignore
        elif isinstance(image, Image.Image):
            return image.size

    @staticmethod
    def fig_to_image(fig):
        """
        å°†matplotlibçš„figureè½¬åŒ–ä¸ºPILçš„Image
        """
        import io

        buf = io.BytesIO()
        fig.savefig(buf, format="png")
        buf.seek(0)
        image = cv2.imdecode(np.frombuffer(buf.getvalue(), np.uint8), cv2.IMREAD_COLOR)

        return image

    @classmethod
    def _plot_block_line(cls, the_ax, shape, np_cumsum, Oij=None):
        """
        è°ƒèŠ‚å¤šå—ç½‘æ ¼çš„æ˜¾ç¤º

        shape[0] æ˜¯è¡Œæ•°ï¼Œshape[1] æ˜¯åˆ—æ•°
        """
        if Oij is None:
            Oij = (0, 0)
        the_ax.xaxis.set_ticks_position("top")  # * å°†xè½´çš„ä½ç½®è®¾ç½®åœ¨é¡¶éƒ¨
        the_ax.tick_params(axis="both")
        the_ax.set_xlim([Oij[1] - 0.5, Oij[1] + shape[1] - 0.5])
        the_ax.set_ylim([Oij[0] - 0.5, Oij[0] + shape[0] - 0.5])
        the_ax.set_xticks(np.arange(Oij[1], Oij[1] + shape[1]))  # ç»˜åˆ¶ç½‘æ ¼ï¼Œæ·»åŠ é¢å¤–çš„è¾¹ç•Œçº¿
        the_ax.set_yticks(np.arange(Oij[0], Oij[0] + shape[0]))  # ç»˜åˆ¶ç½‘æ ¼ï¼Œæ·»åŠ é¢å¤–çš„è¾¹ç•Œçº¿
        the_ax.grid(axis="both", which="both", linewidth=0.5, zorder=-10)  # ç»˜åˆ¶ç½‘æ ¼ï¼Œè®¾å®šç½‘æ ¼çº¿çš„å®½åº¦
        the_ax.margins(0.05)  # * 5% çš„ç©ºç™½
        the_ax.invert_yaxis()  # * yè½´åå‘
        for block_interval in np_cumsum[1:-1]:  # * è¿™é‡Œè¦åå‘åç§»å›æ¥ï¼Œå› ä¸ºå›¾çª—åªè®¤ åŸç‚¹é™„è¿‘çš„åœ°æ–¹
            block_interval -= 0.5
            the_ax.axhline(y=block_interval, dashes=[4, 4], zorder=-5)  # * ç»˜åˆ¶æ°´å¹³çº¿
            the_ax.axvline(x=block_interval, dashes=[4, 4], zorder=-5)  # * ç»˜åˆ¶å‚ç›´çº¿
        pass
        the_ax.axis("equal")

    @staticmethod
    def cut_bbox(
        image: Union[np.ndarray, Image.Image, Any],
        bbox: "np.ndarray",
        str_format="ltrb",
    ):
        """
        image å¾…åˆ‡åˆ†çš„å›¾åƒ
        bbox å¿…é¡»æ˜¯æ•´å‹ï¼Œå¿…é¡»æ˜¯åƒç´ å€¼ï¼Œä¸èƒ½æ˜¯å½’ä¸€åŒ–çš„å€¼
        """

        if type(bbox) not in [np.ndarray]:
            UserWarning(f"bbox å‚æ•°çš„ç±»å‹ä¸º {type(bbox)}, å¹¶æœªæµ‹è¯•è¿‡")
        bboxes: np.ndarray = dict_convert_fn[str_format]["ltrb"](bbox).astype(int)
        list_cut = []
        if isinstance(image, Image.Image):
            for bbox in bboxes:
                list_cut.append(image.crop(bbox))  # type: ignore
        elif isinstance(image, np.ndarray):
            for bbox in bboxes:
                list_cut.append(image[bbox[1] : bbox[3], bbox[0] : bbox[2]])
        else:  # * è¿™é‡Œåº”å½“ä½œä¸º torch.Tensor å¤„ç†
            for bbox in bboxes:
                bbox = bbox.astype(int)
                list_cut.append(image[:, bbox[1] : bbox[3], bbox[0] : bbox[2]])

        return list_cut


class Pretty_Draw:
    outline = 2
    dpi = 200

    @staticmethod
    def draw_affinity(
        mdict_similarity: mdict,  # è®°å½•ä¸¤ä¸¤ä¹‹é—´çš„äº²åˆåº¦çŸ©é˜µ
        dict_img: Union[dict[Any, Image.Image], dict[Any, np.ndarray]] = None,  # type: ignore #todo è¿™é‡Œçš„ç±»å‹å£°æ˜æœ‰é—®é¢˜
        dict_ltrb: dict[Any, np.ndarray] = None,  # type: ignore
        dict_list_cut: dict[Any, list[Union[Image.Image, np.ndarray]]] = None,  # type: ignore
        mdict_pair: mdict = None,  # type: ignore
        mdict_pair_gt: mdict = None,  # type: ignore
        reid_shape: tuple[int, int] = (128, 256),  # * (w,h)
        dpi=200,
    ):
        """
        ç»˜åˆ¶äº²åˆåº¦çŸ©é˜µ

        dict_ltrb å¿…é¡»æ˜¯æœªå½’ä¸€åŒ–çš„ï¼Œä»¥ååšç»Ÿä¸€è§„å®šï¼Œåšå›¾åƒçš„å¯è§†åŒ–æ—¶ï¼Œæ‰€æœ‰é”šæ¡†éƒ½å¿…é¡»æ˜¯æœªå½’ä¸€åŒ–çš„

        mdict_pair_gt æ˜¯GTå€¼

        æ˜¾ç¤ºçš„ç»“æœä¸­ï¼ŒåŠ ç²—ä¸”å¸¦æœ‰è¾¹æ¡†çš„æ˜¯çœŸå€¼
        æ–œä½“çš„æ˜¯æ¨ç†å€¼

        todo ä¹‹åï¼Œåˆ¤æ–­æ˜¯å¦åŒ¹é…æ­£ç¡®ï¼Œå¦‚æœæ¨ç†çš„åŒ¹é…å’ŒçœŸå€¼ç›¸åŒ¹é…ï¼Œåˆ™åœ¨è¾¹æ¡†çš„å³ä¸‹è§’æ‰“ä¸Šä¸€ä¸ªç»¿è‰²çš„âœ…

        Example
        -------

        .. code-block:: python

            # å¯è§†åŒ–ä¸¤å¼ å›¾çš„äº²åˆåº¦çŸ©é˜µ
            from pretty_tools.datastruct import mdict
            mdict_similarity = mdict()
            mdict_similarity[0, 1] = np.random.rand(10, 10) # ç”Ÿæˆä¸€ä¸ª 10*10 çš„äº²åˆåº¦çŸ©é˜µ
            fig = Pretty_Draw.draw_affinity(mdict_similarity)


        """
        from matplotlib.offsetbox import AnnotationBbox, DrawingArea, OffsetImage, TextArea

        z_t = 0.8
        _d_z_t = (1 - z_t) / 2
        assert (dict_img is not None) == (dict_ltrb is not None), "dict_img å’Œ dict_ltrb å¿…é¡»åŒæ—¶ä¸ä¸ºNone æˆ–è€…åŒæ—¶ä¸ºNone"

        ratio_hw = reid_shape[1] / reid_shape[0]
        assert mdict_similarity.dim == 2, "mdictå¿…é¡»æ˜¯äºŒç»´çš„"

        max_m = sum([i.shape[1] for i in mdict_similarity.values()])
        max_n = max([i.shape[0] for i in mdict_similarity.values()])

        if dict_img is not None:
            # * å¦‚æœæ²¡æœ‰ä¼ å…¥åˆ‡åˆ†åçš„å›¾åƒï¼Œåˆ™è¿›è¡Œåˆ‡åˆ†ï¼ˆéœ€è¦ä¼ å…¥ltrbé”šæ¡†ä¿¡æ¯ï¼‰
            dict_list_cut = {}
            for camera_name, img in dict_img.items():
                dict_list_cut[camera_name] = Visiual_Tools.cut_bbox(img, dict_ltrb[camera_name])
        if dict_list_cut is not None:
            # * å¦‚æœå­˜åœ¨åˆ‡åˆ†åçš„å›¾åƒï¼ŒæŒ‰ç…§è¦æ±‚è¿›è¡Œresize
            for list_cut in dict_list_cut.values():
                for i, cut in enumerate(list_cut):
                    if isinstance(cut, Image.Image):
                        list_cut[i] = cut.resize(reid_shape)
                    else:
                        list_cut[i] = cv2.resize(cut, reid_shape)
        fig, axs = plt.subplots(nrows=1, ncols=len(mdict_similarity), figsize=(max_m, max_n), dpi=dpi)
        fig.subplots_adjust(top=1 - _d_z_t - 0.05, bottom=_d_z_t, right=1, left=_d_z_t)  # * top å¤šå‡çš„ 0.05æ˜¯ä¸ºäº†æ”¾å›¾åƒ
        # todo é’ˆå¯¹ len(mdict_similarity) == 1 çš„æƒ…å†µï¼Œè®¾è®¡ä¸€ä¸ªtest
        if len(mdict_similarity) == 1:
            axs = [axs]

        for i, ((camera1, camera2), matrix) in enumerate(mdict_similarity.items()):
            the_ax = axs[i]
            annot_kws = {"fontsize": 18}
            # annot_kws = {}
            draw_heatmap = partial(
                sns.heatmap,
                annot=True,
                cmap="coolwarm",
                vmin=0,
                vmax=1,
                ax=the_ax,
                annot_kws=annot_kws,
            )
            if i != len(mdict_similarity):
                the_ax = draw_heatmap(matrix, cbar=False)  # * ä½¿ç”¨ç»Ÿä¸€çš„é¢œè‰²æ¡
            else:
                the_ax = draw_heatmap(matrix, cbar_ax=[axs[i]])  # * ä½¿ç”¨ç»Ÿä¸€çš„é¢œè‰²æ¡
            # ----------------------------------
            zw = dpi / reid_shape[0] / matrix.shape[1]  ## matrix.shape[1] # æ˜¯ç›¸ä¼¼åº¦çŸ©é˜µæ°´å¹³æ–¹å‘çš„å°ºå¯¸
            zh = dpi / reid_shape[1] / matrix.shape[0]  ## matrix.shape[0] # æ˜¯ç›¸ä¼¼åº¦çŸ©é˜µå‚ç›´æ–¹å‘çš„å°ºå¯¸
            # * è·å–å½“å‰ç½‘æ ¼çš„å¤§å°
            if dict_list_cut is not None:
                for t, image in enumerate(dict_list_cut[camera2]):  # * ç»˜åˆ¶æ¯åˆ—å¯¹åº”çš„å›¾åƒï¼Œï¼ˆä¸Šæ–¹ï¼‰
                    imagebox_w = OffsetImage(image, zoom=zw * z_t / 0.7)  # * 0.7å¯èƒ½æ˜¯åŸºå‡†æ¯”ä¾‹
                    imagebox_w.image.axes = the_ax  # type: ignore
                    the_ax.add_artist(
                        AnnotationBbox(
                            imagebox_w,
                            (t + 0.5, 0),
                            xybox=(t + 0.5, -0.3 * zw / zh),
                            frameon=False,
                        )
                    )
                for t, image in enumerate(dict_list_cut[camera1]):  # * ç»˜åˆ¶æ¯è¡Œå¯¹åº”çš„å›¾åƒï¼Œï¼ˆå·¦ä¾§ï¼‰
                    imagebox_h = OffsetImage(image, zoom=zh * ratio_hw * z_t / 0.7)
                    imagebox_h.image.axes = the_ax  # type: ignore
                    the_ax.add_artist(
                        AnnotationBbox(
                            imagebox_h,
                            (0, t + 0.5),
                            xybox=(-1 * zh / zw, t + 0.5),
                            frameon=False,
                        )
                    )
            if mdict_pair_gt is not None:  # * é«˜äº®åŒ¹é…çš„æ¡†
                for pair in np.array(mdict_pair_gt.loc[camera1, camera2]):
                    text = the_ax.texts[int(pair[0] * matrix.shape[1] + pair[1])]
                    text.set_size(20)
                    text.set_style("italic")
                    text.set_bbox(dict(pad=0, ec="k", fc="none"))
            if mdict_pair is not None:  # * é«˜äº®åŒ¹é…çš„æ¡†
                for pair in np.array(mdict_pair.loc[camera1, camera2]):
                    text = the_ax.texts[int(pair[0] * matrix.shape[1] + pair[1])]
                    text.set_size(20)
                    text.set_weight("bold")
                    text.set_bbox(dict(pad=0, ec="k", fc="none"))
                    # text.set_verticalalignment("baseline")
            the_ax.set_xlabel(camera2, labelpad=0)
            the_ax.set_ylabel(camera1, labelpad=80 * zh / zw)
            the_ax.yaxis.tick_right()  # * yè½´æ ‡ç­¾æ”¾åœ¨å³è¾¹

        fig.colorbar(axs[-1].collections[0], ax=axs, location="right")  # type: ignore # è®¾ç½®æ•´ä¸ªç”»å¸ƒçš„é¢œè‰²æ¡
        return fig
        # fig.savefig("tmp/affinity.jpg")
        # plt.savefig("tmp/affinity.jpg")

    @staticmethod
    def draw_bboxes(
        img,
        bboxes_ltrb: np.ndarray,
        ids: Optional[list[int]] = None,
        colors: Optional[Union[int, tuple[int, int, int], list[tuple]]] = None,  # RGB,
        infos: Optional[list] = None,
        outline=2,
        size_font=24,
        mask: float = 0,
    ) -> Image.Image:
        """
        ä¼ å…¥ä¸€å¼ å›¾ï¼Œä»¥åŠä¸€å¼ å›¾çš„æ ‡æ³¨ä¿¡æ¯ï¼Œè¿›è¡Œç»˜åˆ¶

        Args:

            bboxes : LTRB æ ¼å¼
            ids å¯é€‰
            colors : å¦‚æœæ˜¯ä½¿ç”¨ç»Ÿä¸€çš„é¢œè‰²ï¼Œåˆ™éœ€è¦è¾“å…¥çš„ colors åº”å½“ä¸º tuple
        """
        #! ä»…æ”¯æŒè¿™ä¸€ç§æ ‡æ³¨æ ¼å¼ï¼Œä¸å†åšå…¶ä»–çš„é€‚é…ï¼ˆå¤ªéº»çƒ¦ï¼Œè€Œä¸”æ•ˆç‡ä¸é«˜ï¼‰
        assert bboxes_ltrb.ndim == 2, "æ ¼å¼å¿…é¡»æ˜¯äºŒç»´æ•°ç»„ï¼Œé•¿åº¦ä¸º(n, 4)"
        assert bboxes_ltrb.shape[1] == 4
        if colors is None:
            colors = (255, 255, 255)
        if isinstance(colors, list):
            assert len(colors) == len(bboxes_ltrb), "å¦‚æœæ˜¯ä½¿ç”¨ç»Ÿä¸€çš„é¢œè‰²ï¼Œåˆ™éœ€è¦è¾“å…¥çš„ colors åº”å½“ä¸º tuple"

        bboxes_ltrb = copy.deepcopy(bboxes_ltrb)
        #! ä¸€å®šè¦æ˜¯np.float32æˆ–è€…ç›´æ¥ç”¨int
        if bboxes_ltrb.dtype == np.float64 or bboxes_ltrb.dtype == np.float128:
            bboxes_ltrb = bboxes_ltrb.astype(np.float32)
        bboxes_ltrb = bboxes_ltrb.astype(np.float32)

        if infos is not None:
            assert len(bboxes_ltrb) == len(infos)
        if ids is not None:
            assert len(bboxes_ltrb) == len(ids)

        if isinstance(img, np.ndarray):
            image = Image.fromarray(img)
        elif isinstance(img, Image.Image):
            image = copy.deepcopy(img)
            pass
        else:  # * è§†ä½œä½œä¸º torch.Tensor
            image = Image.fromarray(np.transpose(img.detach().cpu().numpy(), (1, 2, 0)))

        if bboxes_ltrb.ndim == 1:
            bboxes_ltrb = bboxes_ltrb[np.newaxis, :]

        if type(colors) == tuple:
            colors = len(bboxes_ltrb) * [colors]

        # * ç»˜åˆ¶å…·æœ‰é€æ˜åº¦çš„å›¾ç‰‡

        if mask != 0:
            mask = int(255 * mask)
            _image = image.convert("RGBA")
            image = Image.new("RGBA", img.size, (0, 0, 0, 0))  # type: ignore

            colors = [(*color, 255) for color in colors]  # type:ignore
            #! å¦‚æœæœ‰é€æ˜åº¦ï¼Œåˆ™è‡ªä¸Šè€Œä¸‹åœ°ç»˜åˆ¶ï¼Œä¸‹é¢çš„è¦†ç›–ä¸Šé¢çš„
            sort_index = np.argsort(bboxes_ltrb[:, 3])
            colors = [colors[i] for i in sort_index]
            infos = [infos[i] for i in sort_index] if infos is not None else infos
            ids = [ids[i] for i in sort_index] if ids is not None else ids

            bboxes_ltrb = bboxes_ltrb[sort_index]
            # * ç»˜åˆ¶mask
            draw = ImageDraw.Draw(image, mode="RGBA")
            for box, color in zip(bboxes_ltrb, colors):
                draw.rectangle(box, width=outline, outline=color, fill=color[:3] + (mask,))  # type: ignore
            image = Image.alpha_composite(_image, image)
            image = image.convert("RGB")

        draw = ImageDraw.Draw(image, mode="RGB")
        # * ç»˜åˆ¶è¾¹æ¡† ä¸èƒ½å’Œ mask ä¸€èµ·ç»˜åˆ¶ï¼Œä¼šå‡ºç°è¾¹æ¡†è¢«maskè¦†ç›–çš„é—®é¢˜
        for box, color in zip(bboxes_ltrb, colors):  # type: ignore
            draw.rectangle(box, width=outline, outline=color)

        if infos is not None:
            font = ImageFont.truetype(str(path_font_arial), size_font)
            for box, info in zip(bboxes_ltrb, infos):
                draw.text(box[2:4], info, font=font)  # * info ç»˜åˆ¶åœ¨ é”šæ¡†çš„ å³ä¸‹è§’
        if ids is not None:
            font = ImageFont.truetype(str(path_font_arial), size_font)
            for box, _id in zip(bboxes_ltrb, ids):
                draw.text(box[0:2], str(_id), font=font)  # * info ç»˜åˆ¶åœ¨ é”šæ¡†çš„ å·¦ä¸Šè§’
        return image

    @staticmethod
    def draw_bboxes_matplotlib(
        img: Union[np.ndarray, Image.Image],
        np_ltrb: np.ndarray,
        ids: Optional[np.ndarray] = None,  # type: ignore
        str_format: str = "ltrb",  # type: ignore
    ):
        """
        img è¾“å…¥çš„å›¾åƒï¼Œå¯ä»¥æ˜¯cv2æ ¼å¼çš„ï¼Œä¹Ÿå¯ä»¥æ˜¯PILæ ¼å¼çš„
        é»˜è®¤è¾“å…¥çš„æ˜¯ LTRBï¼Œä½†æ˜¯é€šè¿‡ str_format è¯´æ˜æ ¼å¼ï¼Œä¼šè‡ªåŠ¨è¿›è¡Œè½¬æ¢

        è¿”å›çš„æ˜¯ä¸€ä¸ªfigå¯¹è±¡
        """
        import matplotlib.patches as patches

        assert isinstance(np_ltrb, np.ndarray), "å¿…é¡»æ˜¯ndarray"
        assert np_ltrb.ndim == 2
        assert np_ltrb.shape[1] == 4
        np_ltwh = dict_convert_fn[str_format]["ltwh"](np_ltrb)

        w, h = Visiual_Tools.get_wh(img)
        fig = plt.figure(figsize=(w / Pretty_Draw.dpi, h / Pretty_Draw.dpi), dpi=Pretty_Draw.dpi)
        fig.subplots_adjust(left=0, right=1, bottom=0, top=1, wspace=0, hspace=0)
        # fig.figimage(img)  # type: ignore
        ax = fig.gca()
        ax.imshow(img)  # type: ignore
        for ltwh in np_ltwh:
            # xywh = xywh / np.array([w, h, w, h])
            rectangle = patches.Rectangle(ltwh[:2], ltwh[2], ltwh[3], linewidth=1, edgecolor="r", facecolor="none")
            ax.add_patch(rectangle)
            pass
        # fig.savefig("tmp/tmp.jpg")
        return fig

    @staticmethod
    def draw_combine_affinity_mdict(
        mdict_similarity: mdict,
        mdict_pair: mdict = None,  # type: ignore
        mdict_pair_gt: mdict = None,  # type: ignore
        dict_edge: dict = None,  # type: ignore #* ç”¨äºå¯è§†åŒ–çš„å›¾è¿æ¥
        *,
        mdict_pair_dev: mdict = None,  # type: ignore #* å¼€å‘ä¸­çš„å¯è§†åŒ–
    ):
        """
        å’Œ draw_affinity() æœ‰ç‚¹ç±»ä¼¼ï¼Œç»˜åˆ¶çš„æ˜¯ä¸€ä¸ªæ‹“æ‰‘äº²åˆåº¦çŸ©é˜µï¼Œä½†æ˜¯ä¸ºäº†æ–¹ä¾¿ä¸å†æ˜¾ç¤ºç›®æ ‡é”šæ¡†çš„æˆªå›¾

        Args:
            mdict_similarity : "mdictå¿…é¡»æ˜¯äºŒç»´çš„", ä¹‹åä¼šæ”¹æˆå¯ä»¥ä½¿ç”¨ä¸€ä¸ªå¤§çŸ©é˜µï¼Œç°é˜¶æ®µä¸è¿›è¡Œå¤„ç†

        .. code-block:: python

            # å¯è§†åŒ–ä¸‰å¼ å›¾çš„äº²åˆåº¦çŸ©é˜µ
            from pretty_tools.datastruct import mdict
            mdict_similarity = mdict(2)
            mdict_similarity[0, 1] = np.random.rand(10, 10) # ç”Ÿæˆä¸€ä¸ª 10*10 çš„äº²åˆåº¦çŸ©é˜µ
            mdict_similarity[0, 2] = np.random.rand(10, 10) # ç”Ÿæˆä¸€ä¸ª 10*10 çš„äº²åˆåº¦çŸ©é˜µ
            mdict_similarity[1, 2] = np.random.rand(10, 10) # ç”Ÿæˆä¸€ä¸ª 10*10 çš„äº²åˆåº¦çŸ©é˜µ
            fig = Pretty_Draw.draw_combine_affinity(mdict_similarity)


        .. note::

            è¿™ä¸ªè°ƒç”¨å¯èƒ½æœ‰ç‚¹å›°éš¾ï¼Œå› ä¸ºä¸ä¸€å®šå°±æ˜¯ä½¿ç”¨çš„ mdictï¼Œä½¿ç”¨å‰è¿˜è¦è½¬æ¢æˆ mdictã€‚
            todo ä¹‹åæ ¹æ®è¿™ä¸€ç‚¹è¿›è¡Œæ›´æ”¹


        """
        import math

        import matplotlib
        import seaborn as sns
        from pandas import DataFrame

        assert mdict_similarity.dim == 2, "mdictå¿…é¡»æ˜¯äºŒç»´çš„"
        # * å¿…é¡»æ˜¯ä¸¤ä¸¤çš„äº²åˆåº¦çŸ©é˜µï¼Œæ ¡éªŒçŸ©é˜µä¸ªæ•°
        n = math.ceil(math.sqrt(2 * len(mdict_similarity)))
        assert math.comb(n, 2) == len(mdict_similarity), "mdict_similarity çš„é•¿åº¦ä¸ç¬¦åˆè¦æ±‚"
        n_fig = 1
        if mdict_pair is not None:
            n_fig += 1
        if mdict_pair_dev is not None:
            n_fig += 1
        #! åˆå¹¶çŸ©é˜µ
        merge_aff, np_len = graph_enhance.merge_affinity(mdict_similarity)

        # * å¤„ç†ä¸å¤ªå¥½å¤„ç†çš„ mdict_similarity
        # ----------------------------------------

        sum_node = int(sum(np_len))
        np_cumsum = np.cumsum(np.insert(np_len, 0, 0))

        curt_fig = 0
        max_shape_size = sum_node**2
        fig, axes = plt.subplots(1, n_fig, figsize=(sum_node / 3 * n_fig, sum_node / 3), dpi=Pretty_Draw.dpi)
        df = DataFrame(np_enhance.index_value_2d(merge_aff), columns=["x", "y", "value"])
        #! è¿™é‡Œç»˜åˆ¶ ç›¸ä¼¼åº¦éƒ¨åˆ†çš„èŠ‚ç‚¹å›¾
        ax = axes[0] if n_fig != 1 else axes
        cm_aff = matplotlib.colormaps["plasma_r"]  # type: ignore  # tab20b_r # tab20c_r
        scatter_sizes = (5, max_shape_size * 0.5)
        ax = sns.scatterplot(data=df, x="x", y="y", size="value", hue="value", ax=ax, palette=cm_aff, sizes=scatter_sizes, zorder=2)
        sns.move_legend(ax, "upper left", labelspacing=sum_node / 20, ncol=1, frameon=True, bbox_to_anchor=(1, 1), borderaxespad=0)

        Visiual_Tools._plot_block_line(ax, merge_aff.shape, np_cumsum)
        # * ç»˜åˆ¶åº¦çŸ©é˜µ
        if dict_edge is not None:
            combine_list_edge = [v + np_cumsum[k] for k, v in dict_edge.items()]
            np_edge = np.concatenate(combine_list_edge, axis=1)
            del combine_list_edge
            # * è¿™é‡Œxyè¦äº’æ¢ä¸€ä¸‹ï¼Œæ•£ç‚¹å›¾çš„æ¨ªè½´æ˜¯xè½´ï¼Œä½†æ˜¯è¾¹ç´¢å¼•å…³ç³»çš„ç¬¬0è¡Œæ˜¯çºµè½´
            ax.scatter(np_edge[1], np_edge[0], marker=r"$e$", c="green", s=80, zorder=3)

        dict_gt: dict[int, int] = {}  # *  dict{global_index: global_id}
        pair_gt_coo = None
        if mdict_pair_gt is not None:
            pair_gt_coo = mdict.to_sparse(np_cumsum, mdict_pair_gt)
            for index, matched in mdict_pair_gt.items():
                gt_pos = matched[0] + np_cumsum[*[index]]
                dict_gt.update(dict(zip(gt_pos[:, 0], matched[1])))
                dict_gt.update(dict(zip(gt_pos[:, 1], matched[1])))

            cm_gt = matplotlib.colormaps["prism"]  # type: ignore
            dict_color = dict(zip(dict_gt.values(), cm_gt([*dict_gt.values()])))
            dict_color_text_id: dict[int, str] = {i: ("black" if np.sum(v[:3] * [0.299, 0.587, 0.114]) > 0.45 else "white") for i, v in dict_color.items()}

            for index, gt_id in dict_gt.items():
                ax.plot(index, index, "o", color=dict_color[gt_id], markersize=15, zorder=7)  #! åœ¨ dev å›¾çš„ ä¸­å¿ƒçº¿ ä¸Šç»˜åˆ¶å…¨å±€ id å·
                ax.text(index, index, f"{gt_id}", fontsize=10, color=dict_color_text_id[gt_id], ha="center", va="center", zorder=8)

            if dict_edge is not None:
                # * è¿™é‡Œxyè¦äº’æ¢ä¸€ä¸‹ï¼Œæ•£ç‚¹å›¾çš„æ¨ªè½´æ˜¯xè½´ï¼Œä½†æ˜¯è¾¹ç´¢å¼•å…³ç³»çš„ç¬¬0è¡Œæ˜¯çºµè½´
                ax.scatter(np_edge[1], np_edge[0], marker=r"$e$", c="green", s=80, zorder=3)

        dict_result: dict[int, int] = {}  # *  dict{global_index: global_id}
        if mdict_pair is not None:
            curt_fig += 1
            ax_result = axes[curt_fig]
            Visiual_Tools._plot_block_line(ax_result, merge_aff.shape, np_cumsum)

            if pair_gt_coo is not None:
                assert dict_gt is not None
                for index, gt_id in dict_gt.items():
                    ax_result.plot(index, index, "o", color=dict_color[gt_id], markersize=15, zorder=7)  #! åœ¨ dev å›¾çš„ ä¸­å¿ƒçº¿ ä¸Šç»˜åˆ¶å…¨å±€ id å·
                    ax_result.text(index, index, f"{gt_id}", fontsize=10, color=dict_color_text_id[gt_id], ha="center", va="center", zorder=8)
            pair_match_coo = mdict.to_sparse(np_cumsum, mdict_pair).tocoo()

            if mdict_pair_gt is not None:
                for i, j, v in zip(pair_match_coo.row, pair_match_coo.col, pair_match_coo.data):
                    # * éœ€è¦ä¿è¯ä¸»å¯¹è§’çº¿ä¸Šçš„ä¸¤ä¸ªidéƒ½æ˜¯ç›¸åŒçš„ï¼Œè¿™æ ·çš„ç»“æœæ‰æ˜¯æ­£ç¡®çš„,
                    # print(i, j)
                    if i in dict_gt and j in dict_gt:
                        if dict_gt[i] == dict_gt[j]:
                            #! ç”»ä¸äº†emoji æç¤ºæ²¡æœ‰æ‰¾åˆ°è¿™ä¸ªå­—ï¼Œå³ä½¿é‡‡ç”¨äº†è‡ªå·±åŠ è½½è¿›æ¥çš„emojiå­—ä½“
                            # ax_result.text(j, i, r'ğŸ˜„', fontsize=15, fontname="Noto Color Emoji", ha='center', va='center', color="green")
                            ax_result.text(j, i, "âœ”", fontsize=20, ha="center", va="center", color="green")
                            continue
                    ax_result.text(j, i, "âœ–ï¸", fontsize=18, ha="center", va="center", color="red")  #! åœ¨ dev å›¾çš„ ä¸­å¿ƒçº¿ ä¸Šç»˜åˆ¶å…¨å±€ id å·
            else:
                ax_result.plot(pair_match_coo.col, pair_match_coo.row, "o", color="black", markersize=15, zorder=7)  #! åœ¨ dev å›¾çš„ ä¸­å¿ƒçº¿ ä¸Šç»˜åˆ¶å…¨å±€ id å·

            fig.savefig("tmp/tmp.jpg")
            pass

        if mdict_pair_dev is not None:
            curt_fig += 1
            ax_dev = axes[curt_fig]
            list_xy = []
            list_aff = []
            for index, aff in mdict_pair_dev.items():
                index_xy = np.vstack(aff.nonzero())
                tmp = index_xy.T + np_cumsum[*[index]]
                list_xy += tmp.tolist()
                list_xy += tmp[:, ::-1].tolist()
                list_aff += 2 * aff[*index_xy].tolist()

            df_dev = DataFrame(np.array(list_xy), columns=["x", "y"])
            df_dev["value"] = np.array(list_aff)
            ax_dev = sns.scatterplot(data=df_dev, x="x", y="y", size="value", hue="value", ax=ax_dev, palette=cm_aff, sizes=scatter_sizes, size_norm=(0, 1), zorder=2)
            #! å¦‚æœæœ‰gtï¼Œåˆ™åœ¨ dev å›¾çš„ ä¸­å¿ƒçº¿ ä¸Šç»˜åˆ¶å…¨å±€ id å·
            if mdict_pair_gt is not None:
                assert dict_gt is not None
                for index, gt_id in dict_gt.items():
                    ax_dev.plot(index, index, "o", color=dict_color[gt_id], markersize=15, zorder=7)  #! åœ¨ dev å›¾çš„ ä¸­å¿ƒçº¿ ä¸Šç»˜åˆ¶å…¨å±€ id å·
                    ax_dev.text(index, index, f"{gt_id}", fontsize=10, color=dict_color_text_id[gt_id], ha="center", va="center", zorder=8)

            if dict_edge is not None:
                spare_edge_ij = sparse.coo_matrix((np.ones(np_edge.shape[1]), np_edge), shape=(sum_node, sum_node))
                edge_ij_double = ((spare_edge_ij + spare_edge_ij.T) == 2).tocoo()
                edge_ij_single = ((spare_edge_ij - spare_edge_ij.T) == 1).tocoo()
                # * ç»˜åˆ¶åˆå§‹è¾¹
                ax_dev.scatter(edge_ij_single.col, edge_ij_single.row, marker=r"$e$", c="g", s=50, zorder=3)  # * ç”»çš„å°ä¸€ç‚¹
                # * ç»˜åˆ¶åŒè¾¹
                ax_dev.scatter(edge_ij_double.col, edge_ij_double.row, marker=r"$e$", c="c", s=50, zorder=3)  # * ç”»çš„å°ä¸€ç‚¹
                # * ç»˜åˆ¶å…±è½­è¾¹
                ax_dev.scatter(edge_ij_single.T.col, edge_ij_single.T.row, marker=r"$e$", c="blue", s=50, zorder=3)  # * ç”»çš„å°ä¸€ç‚¹

            Visiual_Tools._plot_block_line(ax_dev, merge_aff.shape, np_cumsum)
            sns.move_legend(ax_dev, "upper left", labelspacing=sum_node / 20, ncol=1, frameon=True, bbox_to_anchor=(1, 1), borderaxespad=0)

        sns.despine(fig=fig, left=True, bottom=True)  # * å»æ‰å·¦è¾¹å’Œä¸‹è¾¹çš„è¾¹æ¡†
        return fig

    @classmethod
    def draw_camera_connect_by_combination(
        cls,
        dict_data: dict[str, tuple[Image.Image, list[int]]],
        dict_tidx_ltrb: dict[int, np.ndarray],
        edge_index_pred: np.ndarray,  # é¢„æµ‹çš„å…³è”
        dict_tidx_ctid: Optional[dict[int, int]] = None,
        edge_index_gt: Optional[np.ndarray] = None,  # çœŸå€¼å…³è”è¾¹
        dict_tuple_score: Optional[dict[tuple[int, int], float]] = None,  # æ‰€æœ‰å…³è¿è¾¹çš„å¾—åˆ†ï¼Œä»¥å…ƒç»„å­—å…¸çš„å½¢å¼ç´¢å¼•
        linewidth_TP: int = 1,
        linewidth_FP: int = 1,
        linewidth_FN: int = 1,
        thresh_overlap: float = 0.2,  # * è€ƒè™‘åˆ°ç›®æ ‡å¯èƒ½æ˜¯é‡åˆçš„ï¼Œè¿™é‡Œè®¾ç½®ä¸€ä¸ªé˜ˆå€¼ï¼Œå¦‚æœä¸¤ä¸ªç›®æ ‡çš„iouå¤§äºè¿™ä¸ªé˜ˆå€¼ï¼Œåˆ™åˆ¤æ–­ä¸æ˜¯é”™è¯¯çš„è¿æ¥
    ):
        """
        é’ˆå¯¹å¤šä¸ªç›¸æœºï¼Œç”¨æ’åˆ—ç»„åˆçš„æ–¹å¼æ˜¾ç¤ºä¸¤ä¸¤ç›®æ ‡çš„å…³è”
        å› ä¸ºä¸æ˜¯é«˜æ€§èƒ½éœ€è¦ï¼Œè¿™é‡Œè¿˜æ˜¯ä½¿ç”¨ matplotlib è¿›è¡Œç»˜åˆ¶

        è¿™é‡Œåªæ¥å— Image.Image æ ¼å¼çš„è¾“å…¥ï¼Œä¸å†åšå…¶ä»–é€‚é…

        Args:
            dict_data (dict[str, tuple[Image.Image, list[int]]]) : å›¾åƒæ•°æ®å­—å…¸ï¼Œå­—å…¸çš„é”®æ˜¯ç›¸æœºåç§°ï¼Œå­—å…¸çš„å€¼æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œå…¶ä¸­çš„å…ƒç´ åˆ†åˆ«æ˜¯ :class:`Image.Image` æ ¼å¼çš„å›¾åƒ, :class:`list` çš„å…ƒç´ æ˜¯ è¯¥ç›¸æœºå†…ç›®æ ‡çš„ ``tidx``
            edge_index_pred (np.ndarray, optional) : é¢„æµ‹çš„å…³è”è¾¹. Defaults to None.
            edge_index_gt (np.ndarray, optional) : çœŸå€¼å…³è”è¾¹. Defaults to None. å½“è¯¥å‚æ•°ä¸ä¸º Noneï¼Œåˆ™ä¼šè‡ªåŠ¨åˆ¤æ–­é¢„æµ‹è¾¹æ˜¯å¦æ­£ç¡®ï¼Œæ­£ç¡®çš„è¿æ¥çº¿ä½¿ç”¨ **ç»¿è‰²**ï¼Œé”™è¯¯çš„è¿æ¥çº¿ä½¿ç”¨ **çº¢è‰²**ï¼Œæ¼æ‰çš„è¿æ¥çº¿ä½¿ç”¨ **è“è‰²**
        ä¼šåœ¨è¯¥ç±»ä¸­è‡ªåŠ¨ç»˜åˆ¶é”šæ¡†ï¼Œå› æ­¤éœ€è¦ä¼ å…¥çš„æ˜¯ä¸€ä¸ªæ²¡æœ‰é”šæ¡†çš„åŸå§‹å›¾åƒ
            pair_dataframe (DataFrame, optional) : ç”¨äºå¯è§†åŒ–çš„å…³è”è¾¹. Defaults to None.
            `pair_dataframe.columns=['cid_a', 'cid_b', 'tidx_a', 'tidx_b', 'ctid_a', 'ctid_b', 'score', 'type', 'jid', 'gid']`
            dict_tidx_ctid (dict[int, int], optional) : ç”¨äºæ ‡è®°ç›®æ ‡çš„ ctid å·. Defaults to None.
        example:
            .. code-block::

                cid_a  cid_b  tidx_a  tidx_b  ctid_a  ctid_b  score  type  jid  gid
                0       0      1       2       9       3       2  0.354  Sort   -1   -1
                1       0      1       3      10       4       3  0.995  Sort   -1   -1
                2       0      1       4      11       5       4  0.996  Sort   -1   -1
                3       0      2       0      13       1       1  0.862  Sort   -1   -1
                4       0      2       3      14       4       2  0.964  Sort   -1   -1
                5       0      2       4      15       5       3  1.000  Sort   -1   -1
                6       0      2       6      16       7       4  0.047  Sort   -1   -1
                7       0      2       7      20       8       8  0.000  Sort   -1   -1
                8       1      2       8      16       1       4  0.035  Sort   -1   -1
                9       1      2      10      14       3       2  0.996  Sort   -1   -1
                10      1      2      11      15       4       3  0.137  Sort   -1   -1
                11      1      2      12      20       5       8  1.000  Sort   -1   -1


        example:
            >>> dict_data = {
            'cam1': (img1, ltrb1),
            'cam2': (img2, ltrb2),
            'cam3': (img3, ltrb3),
            }
            # ltrb æ˜¯ np.ndarray[(n, 4), int]
            >>> edge_index_pred = np.array([[ 2,  3,  4,  0,  3,  4,  6,  7,  8, 10, 11, 12],
                                            [ 9, 10, 11, 13, 14, 15, 16, 20, 16, 14, 15, 20]])
            >>> edge_index_gt = np.array([[ 0,  0,  8,  2,  3,  3, 10,  4,  4, 11,  6, 12],
                                          [ 8, 13, 13,  9, 10, 14, 14, 11, 15, 15, 16, 20]])
            >>> fig = Pretty_Draw.draw_camera_connect_by_combination(
                      dict_data,
                      edge_index_pred=edge_index_keep,
                      edge_index_gt=debug_edge_index_gt,
                      )
        """

        # %%
        seq_img, seq_tidx = list(zip(*dict_data.values()))  # type: ignore
        seq_tidx: tuple[list[int]] = seq_tidx
        np_cumsum = np.cumsum([0] + [len(i) for i in seq_tidx])
        dict_tidx_xywh = {tidx: dict_convert_fn["ltrb"]["xywh"](ltrb) for tidx, ltrb in dict_tidx_ltrb.items()}
        n_t = len(dict_tidx_xywh)
        seq_name = [*dict_data.keys()]
        n_row = math.comb(len(seq_img), 2)

        # åˆ†æçœŸå€¼
        if edge_index_gt is not None:
            edge_index_TP, edge_index_FN, edge_index_FP = match_result_check(edge_index_gt, edge_index_pred)

        # return None  # ? debug
        if dict_tuple_score is not None:
            np_score = np.array([*dict_tuple_score.values()])
            np_edge_index = np.array([*dict_tuple_score.keys()]).T
            max_ = max(np_edge_index.max(), np_edge_index.max()) + 1
            adj_score = sparse.coo_matrix((np_score, np_edge_index), shape=(max_, max_))
            adj_score = adj_score + adj_score.T

        # * é¦–å…ˆç»˜åˆ¶é”šæ¡†
        seq_img_with_bbox = []
        for name, (img, list_tidx) in dict_data.items():
            scale = img.width / 1920
            infos = [f"tidx:{i}" for i in list_tidx]
            ids = [dict_tidx_ctid[i] for i in list_tidx] if dict_tidx_ctid is not None else None
            ltrb = np.stack([dict_tidx_ltrb[i] for i in list_tidx])
            vis_img = Pretty_Draw.draw_bboxes(
                img, ltrb, ids=ids, outline=int(scale * 3), size_font=int(scale * 24), infos=infos, mask=0.2
            )  # * åœ¨é”šæ¡†çš„å³ä¸Šè§’æ˜¾ç¤º tidx å·ï¼Œ tidx å·çš„é¡ºåºç”± dict_data ä¸­ç»™å‡º
            seq_img_with_bbox.append(vis_img)

        # %% # * matplotlib figure
        fig, axs = plt.subplots(nrows=n_row, ncols=2, figsize=(25, 6 * n_row), dpi=Pretty_Draw.dpi)
        fig.subplots_adjust(wspace=0.1, hspace=0.2, top=0.95, bottom=0.05, left=0.05, right=0.90)
        ll_axs: list[list[Axes]] = np.array([axs]).tolist() if n_row == 1 else axs.tolist()

        # * ç»˜åˆ¶ç»„åˆå›¾åƒ
        for row, (i_img, j_img) in enumerate(itertools.combinations(range(len(seq_img)), 2)):
            axA = ll_axs[row][0]
            axB = ll_axs[row][1]
            axA.imshow(seq_img_with_bbox[i_img], zorder=1)
            axA.set_title(seq_name[i_img])
            axB.imshow(seq_img_with_bbox[j_img], zorder=1)
            axB.set_title(seq_name[j_img])

            graph_enhance.Utils_Edge.edge_index_filter_by_set(edge_index_TP, (set(seq_tidx[i_img]), set(seq_tidx[j_img])))
            edge_index_ij_TP = graph_enhance.Utils_Edge.edge_index_filter_by_set(edge_index_TP, (set(seq_tidx[i_img]), set(seq_tidx[j_img])))
            edge_index_ij_FP = graph_enhance.Utils_Edge.edge_index_filter_by_set(edge_index_FP, (set(seq_tidx[i_img]), set(seq_tidx[j_img])))
            edge_index_ij_FN = graph_enhance.Utils_Edge.edge_index_filter_by_set(edge_index_FN, (set(seq_tidx[i_img]), set(seq_tidx[j_img])))

            dict_score = None
            if dict_tuple_score is not None:
                score_ij_TP = np.array(adj_score[*edge_index_ij_TP]).reshape(-1) if edge_index_ij_TP.shape[1] != 0 else np.array([])
                score_ij_FP = np.array(adj_score[*edge_index_ij_FP]).reshape(-1) if edge_index_ij_FP.shape[1] != 0 else np.array([])
                score_ij_FN = np.array(adj_score[*edge_index_ij_FN]).reshape(-1) if edge_index_ij_FN.shape[1] != 0 else np.array([])
                dict_score = {"TP": score_ij_TP, "FP": score_ij_FP, "FN": score_ij_FN}

            matplotlib_misc.apply_connect_between_axes_TP_FP_FN(
                (axA, axB),
                {
                    "TP": (np_enhance.enhance_stack([dict_tidx_xywh[i][:2] for i in edge_index_ij_TP[0]]), np_enhance.enhance_stack([dict_tidx_xywh[i][:2] for i in edge_index_ij_TP[1]])),
                    "FP": (np_enhance.enhance_stack([dict_tidx_xywh[i][:2] for i in edge_index_ij_FP[0]]), np_enhance.enhance_stack([dict_tidx_xywh[i][:2] for i in edge_index_ij_FP[1]])),
                    "FN": (np_enhance.enhance_stack([dict_tidx_xywh[i][:2] for i in edge_index_ij_FN[0]]), np_enhance.enhance_stack([dict_tidx_xywh[i][:2] for i in edge_index_ij_FN[1]])),
                },
                dict_score=dict_score,  # type: ignore
                linewidth_FN=linewidth_FN,
                linewidth_TP=linewidth_TP,
                linewidth_FP=linewidth_FP,
            )
            # * ç»˜åˆ¶åˆ†å€¼è¡¨æ ¼
            scale = axB.dataLim.max[0] / 1920

            word = "TP:\n" + "\n".join([f"({i}, {j}) {score:0.3f}" for (i, j), score in zip(edge_index_ij_TP.T, dict_score["TP"])])
            axB.annotate(word, (axB.dataLim.max[0], axB.dataLim.max[1]), xytext=(axB.dataLim.max[0], axB.dataLim.max[1]))

            word = "FP:\n" + "\n".join([f"({i}, {j}) {score:0.3f}" for (i, j), score in zip(edge_index_ij_FP.T, dict_score["FP"])])
            axB.annotate(word, (axB.dataLim.max[0], axB.dataLim.max[1]), xytext=(axB.dataLim.max[0] + scale * 1.2 * Pretty_Draw.dpi, axB.dataLim.max[1]))

            word = "FN:\n" + "\n".join([f"({i}, {j}) {score:0.3f}" for (i, j), score in zip(edge_index_ij_FN.T, dict_score["FN"])])
            axB.annotate(word, (axB.dataLim.max[0], axB.dataLim.max[1]), xytext=(axB.dataLim.max[0] + scale * 2.4 * Pretty_Draw.dpi, axB.dataLim.max[1]))
            pass
        # plt.close("all")

        # fig.savefig("tmp/draw_camera_connect_by_combination.jpg")
        # %%
        return fig

    @classmethod
    def draw_edge_index(
        cls,
        edge_index,
        values=None,
        np_cumsum: Optional[np.ndarray] = None,
        len_graph: Optional[Union[np.ndarray, list[int]]] = None,
        shape: Optional[Union[tuple, list]] = None,
        Oij: Optional[Union[np.ndarray, Sequence[int]]] = None,
    ):
        """
        åªç»˜åˆ¶ä¸€å¼ å›¾ï¼Œç”¨ä»¥è°ƒè¯•å¤§çŸ©é˜µä¸­çš„é‚»æ¥å…³ç³»

        Args:
            edge_index : [description] ä¼ å…¥çš„é‚»æ¥å…³ç³»ï¼Œ **shape** ä¸º :code:`(2, edge_nums)`
            values (np.ndarray, torch.Tensor, optional): å€¼ï¼Œåº”å½“å’Œedge_indexçš„è¾“å…¥é¡ºåºä¸€è‡´ï¼Œå¯æœ‰å¯æ— ï¼Œå…³ç³»åˆ°é‚»æ¥çŸ©é˜µä¸­æ˜¾ç¤ºçš„å¤§å°ï¼Œå¦‚æœä¸ºæ— ï¼Œåˆ™æ‰€æœ‰æ ‡è®°å¤§å°ä¸€è‡´
            np_cumsum (np.ndarray, torch.Tensor, optional): [description]. Defaults to None. å¦‚æœè®¾å®šäº†å€¼ï¼Œåˆ™ç¬¬ä¸€ä¸ªå…ƒç´ å¿…é¡»ä¸º`0`
            Oij: å·¦ä¸Šè§’åæ ‡åç§»é‡

        .. note::
            å¦‚æœè¾“å…¥çš„ä¸æ˜¯ :class:`np.ndarray` ç±»å‹ï¼Œåˆ™ä¼šå°†å…¶åˆ¤æ–­ä¸º :class:`torch.Tensor` ç±»å‹ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸º :class:`np.ndarray` ç±»å‹

        """
        assert edge_index.shape[0] == 2
        if values is not None:
            assert values.shape[0] == edge_index.shape[1]

        edge_index = convert_to_numpy(edge_index)
        values = convert_to_numpy(values)
        np_cumsum = convert_to_numpy(np_cumsum)
        len_graph = convert_to_numpy(len_graph)
        if np_cumsum is None:
            np_cumsum = np.array([0, int(edge_index.max()) + 1])
        if len_graph is not None:
            if isinstance(len_graph, np.ndarray):
                np_cumsum = np.cumsum([0] + len_graph.tolist())
            else:
                np_cumsum = np.cumsum([0] + len_graph)
        if shape is None:
            shape = [edge_index[0].max() + 1, edge_index[1].max() + 1]

        assert len(edge_index) == 2
        df_edge = DataFrame(edge_index.T, columns=["$i$", "$j$"])
        if values is not None:
            df_edge["value"] = values
        else:
            df_edge["value"] = 1  # * å…¨éƒ¨è®¾ç½®é»˜è®¤çš„ 0.5 çš„å¤§å°

        fig = plt.figure(figsize=(shape[1] / 3 + 1, shape[0] / 3), dpi=Pretty_Draw.dpi)

        scatter_sizes = (5, 80)
        ax_edge = sns.scatterplot(data=df_edge, x="$j$", y="$i$", size="value", hue="value", ax=fig.gca(), sizes=scatter_sizes, size_norm=(0, 1), zorder=2)
        Visiual_Tools._plot_block_line(ax_edge, shape, np_cumsum, Oij=Oij)
        fig.subplots_adjust(right=0.8)

        sns.move_legend(ax_edge, "upper left", labelspacing=shape[1] / 20, ncol=1, frameon=True, bbox_to_anchor=(1, 1), borderaxespad=0)
        ax_edge.spines["right"].set_visible(False)
        ax_edge.spines["top"].set_visible(False)
        ax_edge.spines["bottom"].set_visible(False)
        ax_edge.spines["left"].set_visible(False)
        return fig

    @classmethod
    def draw_adj(
        cls,
        adj,
        shape: Optional[Union[tuple, list]] = None,
        np_cumsum: Optional[np.ndarray] = None,
        len_graph: Optional[Union[np.ndarray, list[int]]] = None,
    ):
        """
        ä½¿ç”¨ç»†èŠ‚è¯·çœ‹ :func:`Pretty_Draw.draw_edge_index`

        Example:

        .. image:: http://pb.x-contion.top/wiki/2023_08/15/3_vis_adj_sum.png
            :width: 800px
            :align: center

        Args:
            adj : The adjacency matrix. å¯ä»¥æ˜¯åˆ—è¡¨ï¼Œè¿™æ ·ä¼šä½œä¸ºä¸»å¯¹è§’çº¿ä¸Šçš„æ–¹é˜µè¿›è¡Œå¤„ç†
            shape (tuple or list, optional):
                è¾“å…¥çš„ç¨€ç–çŸ©é˜µæˆ– numpy æ•°ç»„çš„å½¢çŠ¶. é»˜è®¤ä½¿ç”¨ ``adj`` çš„å°ºå¯¸
            np_cumsum (np.ndarray):
                è¾…åŠ©ç»˜çº¿çš„å€¼.
        """
        if isinstance(adj, list):
            # * å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå¿…ç„¶é€šè¿‡ç¨€ç–çŸ©é˜µçš„æ–¹å¼è¿›è¡Œå¯è§†åŒ–
            from pretty_tools.datastruct import np_enhance

            edge_index, values = np_enhance.convert_listadj_to_edgevalue(adj)

        elif isinstance(adj, (sparse.sparray, sparse.spmatrix)):
            adj = convert_to_numpy(adj, sparse_shape=shape)
            adj = adj.tocsr()  # type: ignore
            edge_index = np.stack(adj.nonzero())
            values = np.array(adj[*edge_index]).reshape(-1)
        elif isinstance(adj, np.ndarray):
            adj = convert_to_numpy(adj)
            edge_index = np.indices(adj.shape).reshape(2, -1)
            values = np.array(adj).flatten()
        else:
            adj = convert_to_numpy(adj, sparse_shape=shape)
            edge_index = np.indices(adj.shape).reshape(2, -1)
            values = np.array(adj).flatten()

        if shape is None:
            shape = adj.shape  # type: ignore

        fig = cls.draw_edge_index(edge_index, values, np_cumsum, len_graph, shape=shape)
        return fig

    @classmethod
    def visual_tensor_heatmap(cls, tensor, as_img=False, annot=True):
        """å¯è§†åŒ–å¼ é‡ï¼Œæœ‰è‹¥å¹²ä¸ªæ¨¡å¼å¯ä»¥é€‰æ‹©


        Args:
            tensor (torch.Tensor): è¾“å…¥çš„å¼ é‡
            as_img (bool, optional): æ˜¯å¦å°†å…¶ç»˜åˆ¶æˆå›¾åƒ

        .. note::
            é»˜è®¤å¼ é‡çš„é¢œè‰²é€šé“åœ¨å‰ï¼Œå³ [C, N, M]


        """
        if isinstance(tensor, list):
            from pretty_tools.datastruct import np_enhance

            edge_index, values = np_enhance.convert_listadj_to_edgevalue(tensor)
            list_shape = [t.shape for t in tensor]
            total_shape = np.sum(list_shape, axis=0)
            # * è½¬æ¢æˆç¨ å¯†çŸ©é˜µï¼ˆè¿™ä¸€æ­¥æ²¡å¿…è¦ä¼˜åŒ–äº†ï¼Œæ¯•ç«Ÿç”»å‡ºæ¥çš„å›¾è‚¯å®šæ¯”è¿™ä¸ªçš„ç¨ å¯†çŸ©é˜µè¿˜å¤§ï¼‰
            adj = sparse.coo_matrix((values, (edge_index[0], edge_index[1])), shape=total_shape).todense()
            tensor = torch.from_numpy(adj)

        assert isinstance(tensor, torch.Tensor)
        tensor = tensor.detach().cpu()
        if tensor.shape[0] > 100 or tensor.shape[1] > 100:
            if not as_img:
                raise UserWarning(f"è¾“å…¥çš„å¼ é‡è¿‡å¤§(shape={[*tensor.shape]} æŸä¸ªç»´åº¦å¤§äº 100)ï¼ŒæœªæŒ‡å®š as_img å¯èƒ½ä¼šå¯¼è‡´å†…å­˜å ç”¨è¿‡å¤§")

            pass
        if tensor.ndim == 2:
            fig_size = tensor.shape[::-1]
        else:
            fig_size = tensor.shape[-2:][::-1]

        if as_img:
            fig_size = tuple(np.array([*fig_size]) / 8)  # * è¿™é‡Œæ˜¯ä¸€ä¸ªè°ƒæ•´å¤§å°çš„å‚æ•°ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œè°ƒæ•´
        else:
            if annot:
                fig_size = tuple(np.array([*fig_size]))  # * è¿™é‡Œæ˜¯ä¸€ä¸ªè°ƒæ•´å¤§å°çš„å‚æ•°ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œè°ƒæ•´
            else:
                fig_size = tuple(np.array([*fig_size]) / 2)  # * è¿™é‡Œæ˜¯ä¸€ä¸ªè°ƒæ•´å¤§å°çš„å‚æ•°ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œè°ƒæ•´

        fig = plt.figure(figsize=fig_size, dpi=Pretty_Draw.dpi)

        if tensor.min() < 0:
            cm = matplotlib.colormaps["bwr"]  # type: ignore
        else:
            cm = matplotlib.colormaps["jet"]  # type: ignore

        if as_img:
            ax = sns.heatmap(tensor, center=0, ax=fig.gca(), cmap=cm, square=True, annot=False)
            ax.xaxis.set_ticks_position("top")  # * å°†xè½´çš„ä½ç½®è®¾ç½®åœ¨é¡¶éƒ¨
            labels = ax.get_xticklabels()
            ax.set_xticklabels(labels=labels, rotation=90)
        else:
            ax = sns.heatmap(tensor, center=0, ax=fig.gca(), cmap=cm, square=True, annot=annot, fmt=".2f")
            ax.xaxis.set_ticks_position("top")  # * å°†xè½´çš„ä½ç½®è®¾ç½®åœ¨é¡¶éƒ¨

        return fig

    @classmethod
    def draw_PR_curve(cls, P, R, thresh, cmap="turbo"):
        """
        ç»˜åˆ¶PRæ›²çº¿

        Args:
            P (np.ndarray): precision
            R (np.ndarray): recall
            thresh (np.ndarray): é˜ˆå€¼

        #todo F1 çš„å€¼è¿˜æ²¡æœ‰åœ¨å›¾ä¸Šè¿›è¡Œè¯´æ˜
        """
        from matplotlib.collections import LineCollection
        from matplotlib.colors import BoundaryNorm, ListedColormap, Normalize

        fig = plt.figure(figsize=(8, 7), dpi=3 * Pretty_Draw.dpi)
        ax = fig.gca()

        # * P-R æ›²çº¿ï¼ŒR åº”å½“æ˜¯ x è½´ï¼ŒP åº”å½“æ˜¯ y è½´
        points = np.array([R, P]).T.reshape(-1, 1, 2)
        segments = np.concatenate([points[:-1], points[1:]], axis=1)  # * æœ‰å‡ ä¸ªç‚¹å°±åˆ‡åˆ†æˆå‡ ä¸ªæ®µï¼Œè¿™æ ·æ¯ä¸ªæ®µéƒ½èƒ½æœ‰ä¸€ä¸ªé¢œè‰²
        F1 = 2 * (R * P) / (R + P + 1e-9)
        norm = Normalize(F1.min(), F1.max())
        lc = LineCollection(segments, cmap=cmap, norm=norm)  # type: ignore
        lc.set_array(F1)
        lc.set_linewidth(2)
        line = ax.add_collection(lc)  # type: ignore
        fig.colorbar(line)
        ax.set_xlim(0, 1.05)
        ax.set_ylim(0, 1.05)
        ax.set_xlabel("Recall")
        ax.set_ylabel("Precision")
        # fig.savefig("tmp/tmp.jpg")  #? debug
        # plt.close('all')  #? debug
        return fig

    @classmethod
    def draw_heatmaps(
        cls,
        nrows: int,
        ncols: int,
        tuple_matrix: Union[Sequence[Sequence[np.ndarray]], Sequence[np.ndarray]],
        *,
        figsize: Optional[tuple[int, int]] = None,
        dpi=None,
        annot=False,
        square=False,
        cmap=None,
    ) -> tuple[Figure, np.ndarray[Any, Axes]]:
        """
        åŒæ—¶ç»˜åˆ¶å¤šä¸ªçƒ­å›¾ (åŸºäº seaborn)ã€‚å¹¶ä¸”å…±äº«åŒä¸€ä¸ªé¢œè‰²è½´ï¼Œé€šè¿‡è°ƒç”¨ ``GridSpec`` è§£å†³äº†å…±äº«é¢œè‰²è½´æ—¶åˆ›å»ºæ–°è½´è¿›è€Œå½±å“äº†å…¶ä»–è½´æ˜¾ç¤ºæ•ˆæœçš„é—®é¢˜

        Args:
            nrows (int): è¡Œæ•°
            ncols (int): åˆ—æ•°
            tuple_matrix : çŸ©é˜µå½¢å¼ æˆ–è€… :class:`tuple` å½¢å¼å­˜æ”¾çš„ :class:`np.ndarray` çŸ©é˜µï¼Œç”¨ä»¥å¯è§†åŒ–


        Example
        -------

        .. code-block:: python

            import numpy as np
            from pretty_tools.visualization.draw import Pretty_Draw, Visiual_Tools

            np_rand0 = np.arange(8 * 8)[::-1].reshape(8, 8)
            np_rand1 = np.arange(8 * 8).reshape(8, 8).T
            np_rand2 = np.arange(8 * 8)[::-1].reshape(8, 8).T
            np_rand3 = np.arange(8 * 8).reshape(8, 8)
            fig, axes = Pretty_Draw.draw_heatmaps(2, 2, ((np_rand0, np_rand1), (np_rand2, np_rand3)), figsize=(10, 10), square=True)
            axes[0, 0].set_title("np_rand0")
            axes[0, 1].set_title("np_rand1")
            axes[1, 1].set_title("np_rand3")
            axes[1, 0].set_title("np_rand2")

            visual_att_img = Visiual_Tools.fig_to_image(fig) # æŠŠå›¾åƒè½¬æ¢æˆ np.ndarray
            fig.savefig("tmp/demo.png") #ä¿å­˜å›¾åƒ

        Example
        -------

        .. code-block:: python

            fig, _ = Pretty_Draw.draw_heatmaps(1, 1, (matrix_iou,), square=True, annot=True)
            fig.savefig("tmp/matrix_iou.png")

        .. image:: http://pb.x-contion.top/wiki/2023_09/15/3_demo.png
            :alt: draw_heatmaps_demo
            :width: 500px
            :height: 500px


        Example
        -------
        .. image:: http://pb.x-contion.top/wiki/2023_09/15/3_attention_coefficient.png
            :alt: attention_coefficient
            :width: 500px
            :height: 270px

        """
        import matplotlib.cm as cm
        import matplotlib.colors as mcolors
        from seaborn import cm as sns_cm

        if cmap is None:
            cmap = sns_cm.rocket
        elif isinstance(cmap, str):
            cmap = matplotlib.colormaps[cmap]  # type: ignore

        if dpi is None:
            dpi = cls.dpi
        assert isinstance(nrows, int)
        assert isinstance(ncols, int)

        if nrows == 1:
            tuple_matrix = [tuple_matrix]  # type: ignore

        if figsize is None:
            figsize = (ncols * 5, nrows * 5)  # * figsizeçš„é¡ºåºæ˜¯ å®½é«˜ï¼Œè€Œä¸æ˜¯é«˜å®½

        assert len(tuple_matrix) == nrows, "ä¼ å…¥çš„å¯è§†åŒ–çŸ©é˜µåº”å½“æ˜¯ å…ƒç»„å½¢å¼ï¼Œå…ƒç»„çš„å°ºå¯¸åº”å½“ä¸º (nrows, ncols) "
        assert len(tuple_matrix[0]) == ncols, "ä¼ å…¥çš„å¯è§†åŒ–çŸ©é˜µåº”å½“æ˜¯ å…ƒç»„å½¢å¼ï¼Œå…ƒç»„çš„å°ºå¯¸åº”å½“ä¸º (nrows, ncols) "

        fig = plt.figure(dpi=dpi, figsize=figsize, constrained_layout=True)  # * ä½¿å¾—å„å­å›¾ä¹‹é—´çš„è·ç¦»è‡ªåŠ¨è°ƒæ•´
        # fig = plt.figure(dpi=dpi, figsize=figsize)
        # * æœ¬è´¨ä¸Šåˆ†äº†ä¸¤ä¸ªåŒºåŸŸï¼Œä¸€ä¸ªæ˜¯çƒ­å›¾ï¼Œä¸€ä¸ªæ˜¯é¢œè‰²æ¡ï¼Œé¢œè‰²æ¡è¿™é‡Œåªèƒ½æ”¾åœ¨å³è¾¹(ä¹Ÿå¯ä»¥æ”¹)
        gs = GridSpec(nrows, ncols + 1, width_ratios=[1] * ncols + [0.1], height_ratios=[1] * nrows, figure=fig)
        np_ax = np.zeros((nrows, ncols), dtype=np.object_)

        vmin = np.inf
        vmax = -np.inf
        for i in range(nrows):
            for j in range(ncols):
                adj = tuple_matrix[i][j]
                ax = fig.add_subplot(gs[i, j])
                sns.heatmap(adj, ax=ax, cbar=False, cmap=cmap, annot=annot, square=square)  # * å…±ç”¨é¢œè‰²æ¡
                ax.xaxis.set_ticks_position("top")  # * å°†xè½´çš„ä½ç½®è®¾ç½®åœ¨é¡¶éƒ¨
                if adj.max() > vmax:
                    vmax = adj.max()
                if adj.min() < vmin:
                    vmin = adj.min()
                np_ax[i, j] = ax

        norm = mcolors.Normalize(vmin=vmin, vmax=vmax)
        c_ax = fig.add_subplot(gs[:, -1])

        fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=c_ax)  # colorbar(ax=c_ax) å’Œ  colorbar(cax=c_ax) æ˜¯æœ‰åŒºåˆ«çš„ï¼Œå‰è€…ä¼šç»˜åˆ¶é¢œè‰²æ¡ï¼Œä½†æ˜¯å·¦ä¾§ç•™ç©ºäº†

        return fig, np_ax


def add_right_cax(ax, pad: int, width: int):
    """
    åœ¨ä¸€ä¸ªaxå³è¾¹è¿½åŠ ä¸ä¹‹ç­‰é«˜çš„cax.

    padæ˜¯caxä¸axçš„é—´è·,widthæ˜¯caxçš„å®½åº¦.
    """
    axpos = ax.get_position()
    caxpos = mtransforms.Bbox.from_extents(axpos.x1 + pad, axpos.y0, axpos.x1 + pad + width, axpos.y1)
    cax = ax.figure.add_axes(caxpos)

    return cax
